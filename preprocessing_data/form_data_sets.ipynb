{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature selection functions imported from scikit-learn.\n",
    "#from sklearn.feature_selection import VarianceThreshold\n",
    "import sqlite3 # Database library.\n",
    "import os # Folder management library.\n",
    "import pickle # Serializing module\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Examples from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing database and cursor.\n",
    "star_data_db = sqlite3.connect('star_data.db')\n",
    "star_data_cursor = star_data_db.cursor()\n",
    "\n",
    "# Retrieving star_data from database.\n",
    "classes = ['cep_1o', 'cep_f', 'dsct','eb_ec', 'eb_ed', 'eb_esd', 'lpv_mira_agb_c', 'lpv_mira_agb_o', 'lpv_osarg_agb',\n",
    "           'lpv_osarg_rgb', 'lpv_srv_agb_c', 'lpv_srv_agb_o', 'rrab', 'rrc', 'rrd', 'rre', 't2cep']\n",
    "\n",
    "X, Y = [], []\n",
    "for label, classv in enumerate(classes):\n",
    "    temp_X, temp_Y = [], []\n",
    "    star_data_cursor.execute('SELECT star_features FROM '+classv)\n",
    "    for row in star_data_cursor.fetchall()[:600]:\n",
    "        # Deserializing features.\n",
    "        features = pickle.loads(row[0])\n",
    "        temp_X.append(features)\n",
    "        temp_Y.append([label])\n",
    "    X.append(temp_X)\n",
    "    Y.append(temp_Y)\n",
    "\n",
    "# Randomly shuffle data set for each label.\n",
    "for label, class_set in enumerate(X):\n",
    "    np.random.shuffle(X[label])\n",
    "\n",
    "# Form train, cross-validate, and test sets.\n",
    "# with 380 examples in train set, 110 in test set, and at most 110 in cv set.\n",
    "train_X, test_X, cv_X = [], [], []\n",
    "train_Y, test_Y, cv_Y = [], [], []\n",
    "\n",
    "for label, class_set in enumerate(X):\n",
    "    train_X.append(X[label][0:380])\n",
    "    test_X.append(X[label][380:490])\n",
    "    cv_X.append(X[label][490:601])\n",
    "    \n",
    "    train_Y.append(Y[label][0:380])\n",
    "    test_Y.append(Y[label][380:490])\n",
    "    cv_Y.append(Y[label][490:601])\n",
    "    \n",
    "# Flatten lists\n",
    "train_X = [item for sublist in train_X for item in sublist]\n",
    "test_X = [item for sublist in test_X for item in sublist]\n",
    "cv_X = [item for sublist in cv_X for item in sublist]\n",
    "\n",
    "train_Y = [item for sublist in train_Y for item in sublist]\n",
    "test_Y = [item for sublist in test_Y for item in sublist]\n",
    "cv_Y = [item for sublist in cv_Y for item in sublist]\n",
    "\n",
    "# Close cursor and database    \n",
    "star_data_cursor.close\n",
    "star_data_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Train, Test, CV sets to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08800000000000097, 1.0, 1.0, 0.489010989010989, 6.944630877859366, -0.05576545814126668, 2.1916053390848518, 0.0, 6.042266743868836, 0.30120481927710135, 0.5240963855421766, 0.710843373493987, 0.8373493975903556, 0.9337349397590302, 0.08246852258898776, 0.005479340910972905, 0.0028418699652533906, 0.006062250079006834, 0.0, 1.0012177723951088, 2.3707261226147103, 0.4131451226812992, 0.008407622911196557, 0.0006301700138350181, 0.001762160800906117, 0.0015300389094897848, 0.0, -1.4717197584117114, -2.153745700507042, -1.0848633980523668, 0.00586348791031404, 0.0009843682846886622, 0.0009263988120563587, 0.00014403100305964252, 0.0, 0.8330425550140839, 1.4265006334693706, 0.2137081369086926, -0.00999999999999801, 4.445812853411769e-06, 0.08314061275582775, 15.219890109890107, 0.0039012415127720815, 0.05850000000000044, 0.13736263736263737, 0.03333333333333333, 0.006667323545833725, 0.010904194173481813, 2.2766357398164545, 5.185860340689965e-72, 0.23123358495738228, 0.06391645241542324, 0.1172500000000003, 0.05241088503188859, -0.03688383017046432, 3.9062000000003536, -1.4454749184274247, 0.05937646711653252, 0.8949012859727461, 0.7489689632160481, 1.4594288362068446, 1.7387604381521329, 1.2862316539108578, -0.6912241758241784]]\n"
     ]
    }
   ],
   "source": [
    "# Initializing database and cursor.\n",
    "star_sets_db = sqlite3.connect('star_data_sets.db')\n",
    "star_sets_cursor = star_sets_db.cursor()\n",
    "\n",
    "# Initializing table--(star type) and data type--(BLOB).\n",
    "star_sets_cursor.execute(\"CREATE TABLE IF NOT EXISTS train_set(X BLOB, Y BLOB)\")\n",
    "star_sets_cursor.execute(\"CREATE TABLE IF NOT EXISTS test_set(X BLOB, Y BLOB)\")\n",
    "star_sets_cursor.execute(\"CREATE TABLE IF NOT EXISTS cv_set(X BLOB, Y BLOB)\")\n",
    "\n",
    "# Serializing Data so that it can be stored in database.\n",
    "train_X_pickled = pickle.dumps(train_X, pickle.HIGHEST_PROTOCOL)\n",
    "train_Y_pickled = pickle.dumps(train_Y, pickle.HIGHEST_PROTOCOL)\n",
    "test_X_pickled = pickle.dumps(test_X, pickle.HIGHEST_PROTOCOL)\n",
    "test_Y_pickled = pickle.dumps(test_Y, pickle.HIGHEST_PROTOCOL)\n",
    "cv_X_pickled = pickle.dumps(cv_X, pickle.HIGHEST_PROTOCOL)\n",
    "cv_Y_pickled = pickle.dumps(cv_Y, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Storing star_data in database for future reference.\n",
    "star_sets_cursor.execute(\"INSERT INTO train_set(X, Y) VALUES (?,?)\",\n",
    "                         (sqlite3.Binary(train_X_pickled), sqlite3.Binary(train_Y_pickled)))\n",
    "star_sets_cursor.execute(\"INSERT INTO test_set(X, Y) VALUES (?,?)\",\n",
    "                         (sqlite3.Binary(test_X_pickled), sqlite3.Binary(test_Y_pickled)))\n",
    "star_sets_cursor.execute(\"INSERT INTO cv_set(X, Y) VALUES (?,?)\",\n",
    "                         (sqlite3.Binary(cv_X_pickled), sqlite3.Binary(cv_Y_pickled)))\n",
    "star_sets_db.commit()\n",
    "\n",
    "# Close cursor and database    \n",
    "star_sets_cursor.close\n",
    "star_sets_db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "Y = MultiLabelBinarizer().fit_transform(y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Removing features with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "[  1.           6.74065412   2.26944314   9.00431076   2.01618904\n",
      "   0.25089575   2.51641834  -0.19544798   0.42600746   1.57417675\n",
      "   0.72741717   0.48184163  -0.42631486   0.14521918  15.29753125\n",
      "   1.93854131   0.04479627  -0.10384533   3.85524     -1.41473181\n",
      "   2.0305565   -0.59214443]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "#X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "print(len(X))\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "J = sel.fit_transform(X)\n",
    "\n",
    "print(J[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [3], [3], [3], [3], [3], [3], [3], [3], [3], [3], [4], [4], [4], [4], [4], [4], [4], [4], [4], [4], [5], [5], [5], [5], [5], [5], [5], [5], [5], [5], [6], [6], [6], [6], [6], [6], [6], [6], [6], [6], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [9], [9], [9], [9], [9], [9], [9], [9], [9], [9], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [12], [12], [12], [12], [12], [12], [12], [12], [12], [12]]\n",
      "[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] != [12]:\n",
    "        y[i] = [0]\n",
    "    if y[i] == [12]:\n",
    "        y[i] = [1]\n",
    "print(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "hi1\n",
      "2\n",
      "hi2\n",
      "3\n",
      "hi3\n",
      "['hi1', 'hi2', 'hi3']\n",
      "['hi1', 'hi2']\n",
      "['hi1', 'hi2', 'hi3']\n"
     ]
    }
   ],
   "source": [
    "a = ['hi1', 'hi2', 'hi3']\n",
    "\n",
    "for i, item in enumerate(a):\n",
    "    print(i+1)\n",
    "    print(item)\n",
    "    \n",
    "print(a)\n",
    "print(a[:2])\n",
    "print(a[:45645555])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hi1', 'hi2', 'hi3'], ['hi1', 'hi2', 'hi3']]\n",
      "['hi1', 'hi3']\n"
     ]
    }
   ],
   "source": [
    "a = ['hi1', 'hi2', 'hi3']\n",
    "\n",
    "b = []\n",
    "b.append(a)\n",
    "b.append(a)\n",
    "print(b)\n",
    "np.random.shuffle(b[0])\n",
    "print(b[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'd']\n"
     ]
    }
   ],
   "source": [
    "c = ['a', 'b', 'c', 'd']\n",
    "e = c[2:45646]\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 1, 2, 1, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "r = [[1,2,3],[1,2],[1,4,5,6,7]]\n",
    "r = [item for sublist in r for item in sublist]\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
